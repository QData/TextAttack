{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TextAttack & AllenNLP \n",
    "\n",
    "This is an example of testing adversarial attacks from TextAttack on pretrained models provided by AllenNLP. \n",
    "\n",
    "In a few lines of code, we load a sentiment analysis model trained on the Stanford Sentiment Treebank and configure it with a TextAttack model wrapper. Then, we initialize the TextBugger attack and run the attack on a few samples from the SST-2 train set.\n",
    "\n",
    "For more information on AllenNLP pre-trained models: https://docs.allennlp.org/models/main/\n",
    "\n",
    "For more information about the TextBugger attack: https://arxiv.org/abs/1812.05271"
   ],
   "metadata": {
    "id": "JPVBc5ndpFIX"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/QData/TextAttack/blob/master/docs/2notebook/Example_2_allennlp.ipynb)\n",
    "\n",
    "[![View Source on GitHub](https://img.shields.io/badge/github-view%20source-black.svg)](https://github.com/QData/TextAttack/blob/master/docs/2notebook/Example_2_allennlp.ipynb)"
   ],
   "metadata": {
    "id": "AyPMGcz0qLfK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip install allennlp allennlp_models > /dev/null"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from allennlp.predictors import Predictor\n",
    "import allennlp_models.classification\n",
    "\n",
    "import textattack\n",
    "\n",
    "class AllenNLPModel(textattack.models.wrappers.ModelWrapper):\n",
    "    def __init__(self):\n",
    "        self.predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/basic_stanford_sentiment_treebank-2020.06.09.tar.gz\")\n",
    "        self.model = self.predictor._model\n",
    "        self.tokenizer = self.predictor._dataset_reader._tokenizer\n",
    "\n",
    "    def __call__(self, text_input_list):\n",
    "        outputs = []\n",
    "        for text_input in text_input_list:\n",
    "            outputs.append(self.predictor.predict(sentence=text_input))\n",
    "        # For each output, outputs['logits'] contains the logits where\n",
    "        # index 0 corresponds to the positive and index 1 corresponds \n",
    "        # to the negative score. We reverse the outputs (by reverse slicing,\n",
    "        # [::-1]) so that negative comes first and positive comes second.\n",
    "        return [output['logits'][::-1] for output in outputs]\n",
    "\n",
    "model_wrapper = AllenNLPModel()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-10-14 22:12:09.002867: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-14 22:12:09.002925: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/root/anaconda3/envs/textattackenv/lib/python3.7/site-packages/allennlp/tango/__init__.py:18: UserWarning: AllenNLP Tango is an experimental API and parts of it might change or disappear every time we release a new version.\n",
      "  \"AllenNLP Tango is an experimental API and parts of it might change or disappear \"\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_br6Xvsif9SA",
    "outputId": "224cc851-0e9d-4454-931c-64bd3b7af400"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from textattack.datasets import HuggingFaceDataset\n",
    "from textattack.attack_recipes import TextBuggerLi2018\n",
    "from textattack.attacker import Attacker\n",
    "\n",
    "\n",
    "dataset = HuggingFaceDataset(\"glue\", \"sst2\", \"train\")\n",
    "attack = TextBuggerLi2018.build(model_wrapper)\n",
    "\n",
    "attacker = Attacker(attack, dataset)\n",
    "attacker.attack_dataset()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mglue\u001b[0m, subset \u001b[94msst2\u001b[0m, split \u001b[94mtrain\u001b[0m.\n",
      "textattack: Unknown if model of class <class 'allennlp.models.basic_classifier.BasicClassifier'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  CompositeTransformation(\n",
      "    (0): WordSwapRandomCharacterInsertion(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (1): WordSwapRandomCharacterDeletion(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (2): WordSwapNeighboringCharacterSwap(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (3): WordSwapHomoglyphSwap\n",
      "    (4): WordSwapEmbedding(\n",
      "        (max_candidates):  5\n",
      "        (embedding):  WordEmbedding\n",
      "      )\n",
      "    )\n",
      "  (constraints): \n",
      "    (0): UniversalSentenceEncoder(\n",
      "        (metric):  angular\n",
      "        (threshold):  0.8\n",
      "        (window_size):  inf\n",
      "        (skip_text_shorter_than_window):  False\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): RepeatModification\n",
      "    (2): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using /tmp/tfhub_modules to cache modules.\n",
      "2021-10-14 22:12:28.147320: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-10-14 22:12:28.147421: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-10-14 22:12:28.147487: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DG9XW4Q2): /proc/driver/nvidia/version does not exist\n",
      "2021-10-14 22:12:28.147913: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-14 22:12:31.299094: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:  10%|█         | 1/10 [00:07<01:10,  7.80s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[Negative (95%)]] --> [[Positive (93%)]]\n",
      "\n",
      "[[hide]] new secretions from the parental units \n",
      "\n",
      "[[concealing]] new secretions from the parental units \n",
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 1 / 0 / 2:  20%|██        | 2/10 [00:08<00:32,  4.06s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[Negative (96%)]] --> [[[FAILED]]]\n",
      "\n",
      "contains no wit , only labored gags \n",
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 2 / 1 / 4:  40%|████      | 4/10 [00:08<00:13,  2.23s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "[[Positive (100%)]] --> [[[FAILED]]]\n",
      "\n",
      "that loves its characters and communicates something rather beautiful about human nature \n",
      "\n",
      "\n",
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "[[Positive (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "remains utterly satisfied to remain the same throughout \n",
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 2 / 1 / 5:  50%|█████     | 5/10 [00:09<00:09,  1.97s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "[[Negative (98%)]] --> [[Positive (52%)]]\n",
      "\n",
      "on the [[worst]] [[revenge-of-the-nerds]] clichés the filmmakers could [[dredge]] up \n",
      "\n",
      "on the [[pire]] [[reveng-of-the-nerds]] clichés the filmmakers could [[dragging]] up \n",
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 3 / 1 / 6:  60%|██████    | 6/10 [00:10<00:07,  1.80s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "[[Negative (99%)]] --> [[[FAILED]]]\n",
      "\n",
      "that 's far too tragic to merit such superficial treatment \n",
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 4 / 1 / 8:  80%|████████  | 8/10 [00:13<00:03,  1.68s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "[[Positive (98%)]] --> [[Negative (62%)]]\n",
      "\n",
      "[[demonstrates]] that the [[director]] of such [[hollywood]] blockbusters as patriot games can still [[turn]] out a [[small]] , personal [[film]] with an emotional [[wallop]] . \n",
      "\n",
      "[[shows]] that the [[directors]] of such [[tinseltown]] blockbusters as patriot games can still [[turning]] out a [[tiny]] , personal [[movies]] with an emotional [[batting]] . \n",
      "\n",
      "\n",
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "[[Positive (90%)]] --> [[[FAILED]]]\n",
      "\n",
      "of saucy \n",
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 5 / 1 / 9:  90%|█████████ | 9/10 [00:13<00:01,  1.54s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "[[Negative (99%)]] --> [[[FAILED]]]\n",
      "\n",
      "a depressed fifteen-year-old 's suicidal poetry \n",
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 5 / 1 / 10: 100%|██████████| 10/10 [00:14<00:00,  1.42s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "[[Positive (79%)]] --> [[Negative (65%)]]\n",
      "\n",
      "are more [[deeply]] thought through than in most ` right-thinking ' films \n",
      "\n",
      "are more [[seriously]] thought through than in most ` right-thinking ' films \n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 4      |\n",
      "| Number of failed attacks:     | 5      |\n",
      "| Number of skipped attacks:    | 1      |\n",
      "| Original accuracy:            | 90.0%  |\n",
      "| Accuracy under attack:        | 50.0%  |\n",
      "| Attack success rate:          | 44.44% |\n",
      "| Average perturbed word %:     | 20.95% |\n",
      "| Average num. words per input: | 9.5    |\n",
      "| Avg num queries:              | 34.67  |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7fa8ab6f1110>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7fa89656f0d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7fa89022f750>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7fa8ab6f1350>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7fa88fe0fc90>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7fa89904f210>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7fa8ab6ded50>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7fa89863e090>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7fa898a2c850>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7fa898bd09d0>]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MDRWI5Psb85g",
    "outputId": "db7f8f94-0d78-45ea-a7ac-e12167c28365"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[TextAttack] Model Example: AllenNLP",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('textattackenv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "interpreter": {
   "hash": "fc5ab09622b7bfb4149cc58797f29fb87be6e83da02577a1409a3ac75aa37554"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}